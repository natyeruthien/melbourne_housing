---
title: "Melbourne Housing"
author:
  - Natalia Korai
  - Andriani Panagi
  - Waqar Aziz Sulaiman
date: "`r Sys.Date()`"
output: html_document
---

## Import the data set

```{r}
df <- read.csv("C:/Users/ntbna/Downloads/Spring Semester 2023/DSC532/Regression PROJECT/melb_data.csv")
head(df) # 1st six observations

# Preprocessing
cat('Rows:', nrow(df), 'Columns:', ncol(df),'\n') # number of rows and columns
cat('Duplicates:', nrow(df[duplicated(df), ])) # check for duplicates rows
```

```{r}
library(dplyr) # package for %>%
library(tidyr) # package for fill

```

## Missing Values

```{r}
sapply(df, function(x) sum(is.na(x))) # number of missing values for each column
```

```{r}
library('VIM')
library(dplyr)
#for the column car fill the missing values with the median for the column car/ with downup for the YearBuilt
df$Car[is.na(df$Car)] <- median(df$Car, na.rm = T)
df <- df %>% fill(YearBuilt, .direction = 'downup')
boxplot(df$Landsize, na.rm = TRUE)
boxplot(df$BuildingArea, na.rm = TRUE)
```

```{r}
# Identify row number of extreme values
extreme_row <- which(df$Landsize > 25000) 
# Remove extreme values from the Landsize column
df <- df[-c(extreme_row), ]

# Identify row number of extreme values
extreme_row <- which(df$BuildingArea > 1800) 
# Remove extreme value from the BuildingArea column
df <- df[-c(extreme_row), ]

##Column LANDSIZE
#set as nan values the values that are less than 3 in landsize
df$Landsize[df$Landsize <= 3] <- NA 
# fill the nan values with knn
df <- kNN(df,variable = 'Landsize',dist_var = c('Rooms', 'Bathroom', 'Bedroom2', 'BuildingArea','Price','Type'),k=5)

##BUILDLING AREA
#set as nan values the values that are less than 3 in buildingarea
df$BuildingArea[df$BuildingArea <= 3] <- NA 
#fill the nan values with knn
df <- kNN(df,variable = 'BuildingArea',dist_var = c('Rooms', 'Bathroom', 'Bedroom2','BuildingArea','Price','Landsize'),k=5)
```

## Type of the columns

```{r}
str(df) # check the type of each column
```

## Summary statistics

```{r}
# summary for the numerical features
summary(df[,-c(1,2,4,6,7,8,17,20)])
```

Some columns have quite large range; BuildingArea (size of building) has 44515 range, YearBuilt's one is 822, Landsize has 433014, the Propertycount has 21401, as well as price has minimum 85,000 and maximum value 9,000,000.

```{r}
df <- df[,-c(22,23)] #Drop Logical Vectors
```

## Unique Values

```{r}
#how many unique values each column has
number_uniques = c()
for (i in 1:21){
  number_uniques[i] = length(unique(df[,i]))
}
number_uniques = as.data.frame(number_uniques)
number_uniques$col = colnames(df)
number_uniques$index = 1:21
number_uniques
```

Suburb, Address, SellerG, CoouncilArea are categorical columns which cannot be transformed into dummy variables, since the number of their unique values is large. Thus, we will either drop them or make into further processing in order to manipulate them later in the analysis.

## Outliers

```{r}
# check for outliers for numerical (excluding those which has small number of unique) 
find_outliers <- function(x){
  H=1.5 * IQR(x)
  number <- sum(x < (quantile(x)[2]-H)) + sum(x > (quantile(x)[4]+H))
  number
}

df_continuous <- df[,c(5, 9, 10, 14, 15, 16, 18, 19, 21)]
outliers=c()
for (i in 1:9){
  outliers[i]=find_outliers(df_continuous[1:13568,i])
}

# percentage of outliers for each of the above columns
outliers_tois100=as.data.frame(round(((outliers/13568)*100),2)) 
# Add the name of each column
outliers_tois100$col=colnames(df_continuous) 
outliers_tois100
```


Although the outliers are less than 5% of the overall data we cannot say if they can be considered negligible, since they are may located far from the whiskers and generally from the other data points. However, we could drop the very extreme ones (either the maximum or minimum ones, in order to make data a bit more stable) and not affect much the performance of the machine learning algorithms.

```{r}
par(mfrow=c(3,3))

# Creation of boxplots for all the numerical variables
boxplot(x=df_continuous[,1],main = "Price",col = "red")
boxplot(x=df_continuous[,2],main = "Distance",col = "red")
boxplot(x=df_continuous[,3],main = "Postcode",col = "red")
boxplot(x=df_continuous[,4],main = "Landsize",col = "red")
boxplot(x=df_continuous[,5],main = "Buldingarea",col = "red")
boxplot(x=df_continuous[,6],main = "Year of Built",col = "red")
boxplot(x=df_continuous[,7],main = "Lattidute",col = "red")
boxplot(x=df_continuous[,8],main = "Longtitute",col = "red")
boxplot(x=df_continuous[,9],main = "Property count",col = "red")

# Bar plot for the column car
barplot(table(df$Car), ylab= 'Number of carspots')
```

We verify that these columns have some outliers. There are cases where there are outliers, either much greater than the upper whisker, or much lower than the lower whisker. Specifically, the maximum of the columns Landsize and BuldingArea is too high, and the minimum of the YearBuilt is quite lower than the other values. Thus, we will investigate the behaviour of these features without these extreme values.

```{r}
# boxplots without the most extreme values of the columns LandSize, BuildingArea, and YearBuilt
par(mfrow=c(1,3))
boxplot(df$Landsize[df$Landsize != max(df$Landsize)], ylab='Land size')
boxplot(df$BuildingArea[df$BuildingArea != max(df$BuildingArea)], ylab='Building Size')
boxplot(df$YearBuilt[df$YearBuilt != min(df$YearBuilt)], ylab='Year Built')
```

However there are many outliers, there is some progress in the range of data of these columns, especially for the column YearBuilt. We decided to drop the rows where the Landsize is greater than or equal to 1000, or BuildingArea is more than or equal to 600 or YearBuilt is equal to its maximum.

```{r}
# drop the most of the extreme outlies of the columns BuildingArea, Landsize, and YearBuilt
df <- df[(df$BuildingArea < 600) & (df$Landsize < 1000) & (df$YearBuilt) != min(df$YearBuilt),]
summary(df[,c(14, 15, 16)])
```

BuldingArea (size of building) has now 590 range (whereas it had 44515 before), YearBuilt has 168 (822 before) and Landsize has 994 (433014 before).

```{r}
cat('Rows after dropping very extreme values:', nrow(df))
```

## Distribution of the Price

The price is positively skewed

```{r}
# The histogram of the price
hist(df_continuous[,1],main="Price Frequency",xlab="Price",breaks=20)

# For the price QQplot
par(mfrow=c(1,1))
qqnorm(y =df_continuous[,1], main = "Q-Q plot of price")
qqline(y = df_continuous[,1])
```

## Distributions of the numerical columns

```{r}
# histogram for the distance for the distance
par(mfrow=c(1,2))
h <- hist(df_continuous[,2],breaks = "scott",main = "Distribution ",xlab = "Distance",col = "grey",freq = TRUE)
h <- hist(df_continuous[,2],breaks = "scott",main = "Distribution ",xlab = "Distance",col = "grey",freq = FALSE)
lines(density(df_continuous[,2]), col = 2, lwd = 2)

# qqplot for the distance 
par(mfrow=c(1,1))
qqnorm(y =df_continuous[,2], main = "Q-Q plot of distance")
qqline(y = df_continuous[,2])

# histogram for the landsize
par(mfrow=c(1,2))
h <- hist(df_continuous[,4],breaks = "scott",main = "Distribution ",xlab = "Land size",col = "grey",freq = TRUE)
h <- hist(df_continuous[,4],breaks = "scott",main = "Distribution ",xlab = "Land size",col = "grey",freq = FALSE)
lines(density(df_continuous[,4]), col = 2, lwd = 2)

#qqplot for the landsize 
par(mfrow=c(1,1))
qqnorm(y =df_continuous[,4], main = "Q-Q plot of landsize")
qqline(y = df_continuous[,4])

# histogram for the bulding area
par(mfrow=c(1,2))
h <- hist(df_continuous[,5],breaks = "scott",main = "Distribution ",xlab = "Building area",col = "grey",freq = TRUE)
h <- hist(df_continuous[,5],breaks = "scott",main = "Distribution ",xlab = "Building area",col = "grey",freq = FALSE)
lines(density(df_continuous[,5]), col = 2, lwd = 2)

#qqplot for the builiding area 
par(mfrow=c(1,1))
qqnorm(y =df_continuous[,5], main = "Q-Q plot of building area")
qqline(y = df_continuous[,5])

#histogram for year of built
par(mfrow=c(1,2))
h <- hist(df_continuous[,6],main = "Distribution ",xlab = "Year of Built",col = "grey",freq = TRUE)
h <- hist(df_continuous[,6],main = "Distribution ",xlab = "Year of Built",col = "grey",freq = FALSE)
lines(density(df_continuous[,6]), col = 2, lwd = 2)

# qqplot for year of built 
par(mfrow=c(1,1))
qqnorm(y =df_continuous[,6], main = "Q-Q plot of Year of Built")
qqline(y = df_continuous[,6])

# histogram for longtitute
par(mfrow=c(1,2))
h <- hist(df_continuous[,8],main = "Distribution ",xlab = "Longtidute",col = "grey",freq = TRUE)
h <- hist(df_continuous[,8],main = "Distribution ",xlab = "Longtidute",col = "grey",freq = FALSE)
lines(density(df_continuous[,8]), col = 2, lwd = 2)

# qqplot for longtitute
par(mfrow=c(1,1))
qqnorm(y =df_continuous[,8], main = "Q-Q plot of Longtitute")
qqline(y = df_continuous[,8])

# histogram for lattidute
par(mfrow=c(1,2))
h <- hist(df_continuous[,7],main = "Distribution ",xlab = "Lattidute",col = "grey",freq = TRUE)
h <- hist(df_continuous[,7],main = "Distribution ",xlab = "Lattidute",col = "grey",freq = FALSE)
lines(density(df_continuous[,7]), col = 2, lwd = 2)

#qqplot for lattitute
par(mfrow=c(1,1))
qqnorm(y =df_continuous[,7], main = "Q-Q plot of Lattitute")
qqline(y = df_continuous[,7])
```

## Investigate the column Address

```{r}
# the Address has data either 3 or 4 strings
library(stringr)
df[,22:25] <- str_split_fixed(df$Address, ' ', 4)
names(df)

# check for any missing values in the useful column, which is the name of Address (excluding the number and St/Rd etc)
nrow(df[!is.na(df$V23),])

df <- df[-c(2,22,24,25)]
colnames(df)[colnames(df) == 'V23'] <- 'Address'
length(unique(df$Address)) 
```

Since we have a very large number of unique addresses we cannot visualize the data based on this variable. 

## Transform the column Date (date sold)

```{r}
library(lubridate)
df$Date <- strptime(as.character(df$Date), "%d/%m/%Y")
df$Day <- weekdays(df$Date)
df$Year <- year(df$Date)
df$Month <- month(df$Date, label = T)
df <- subset(df, select = -c(Date))
```

## Drop categorical columns which contain many unique values

```{r}
df <- subset(df, select = -c(Suburb, SellerG, CouncilArea, Address))
```

## Correlation between variables

```{r}
library(corrplot)
corrplot(cor(df[,-c(2,4,15,17,19)]))
```

* Rooms correlated with:
  * Price
  * Distance
  * Bedroom2 (strongly)
  * Bathroom
  * Car
  * Landsize
  * BuildingAre (strongly)
* Price correlated with:
  * Distance (negatively)
  * Bedroom2
  * Bathroom
  * Car
  * Landsize
  * BuildingArea (strongly)
  * YearBuilt (negatively)
  * Lattitude (negatively)
  * Longtitude
* Distance is correlated with:
  * Postcode
  * Bedroom2
  * Car
  * Landsize
  * YearBuilt
  * Longtitude
  * Year
* Postcode is correlated with:
  * Lattitude (negatively)
  * Longtitude
* Bedroom2 is correlated with:
  * Bathroom
  * Car
  * Landsize
  * BuildingArea (strongly)
* Bathroom is correlated with:
  * Car
  * Landsize
  * BuildingArea (strongly)
* Car
  * Landsize
  * BuildingArea
* Landsize is correlated with:
  * BuildingArea
* Lattitude and Longtitude are negatively correlated.

```{r}
pairs(df[,-c(2,4,15,17,19)])
pairs(~ Price +Rooms +Car +Distance +Bathroom +Landsize +BuildingArea +YearBuilt +Lattitude +Longtitude +Propertycount, data = df)
```

* We can observe that the price increases while the number of rooms increases as well.
* The price of accomodations which are located near the Central Business District (CBD) varies, whereas those which are far from the CBD cost much less.
* In 2017 the only houses which are sold are located near the CBD.
* There is no evidence to prompt us to make any transformation on some of the predictors.

```{r}
#apply log transformation on the price 
pairs(~ log(Price) +Rooms +Car +Distance +Bathroom +Landsize +BuildingArea +YearBuilt, data = df)
```

```{r}
# combine features into multiple plots

library(ggplot2)
qplot(Distance, data = df, geom = "histogram", fill = Type)
qplot(Distance, Price,  data = df, color = Type)
qplot(Distance, Price,  data = df, color = Method)
qplot(Distance, Price,  data = df, color = Regionname)
```

* The histogram shows that the most of accommodations of the dataset are houses, cottages, villas, semi, or terraces (type h). Also, few ones of every type are far from CBD.
* Observing the plots of Price and Distance we can say that there is a pattern, which it represents that accommodations located far from the CBD have low price, whereas the houses near the CBD have a range of price, from very low to very high amount.
* Based on type of the accommodation, houses, cottages, villas, semi, or terraces (type h) are the most expensive and the distance from the CBD varies, while the other 2 types, units, or duplexes (type u) and townhouses (type t) have low prices and they are near the CBD.

```{r}
# see how many values there are in each category of the two columns: method and regionname
meth <- sort(table(df$Method), decreasing = T)
reg <- sort(table(df$Regionname), decreasing = T)
```

```{r}
# bar plots of the frequency for the columns method and regionname

library("RColorBrewer")
barplot(sort(table(df$Method), decreasing = T), col= brewer.pal(n = 5, name = "GnBu"), names = F, main = 'Frequency of house sells based on method')
legend("center", legend = names(meth), fill =brewer.pal(n = 5, name = "GnBu"))

barplot(sort(table(df$Regionname), decreasing = T), col= brewer.pal(n = 8, name = "GnBu"), names = F, main ='Frequency of house sells in each region' )
legend("topright", legend = names(reg), fill =brewer.pal(n = 8, name = "GnBu"))
```

* Most of the houses have been sold conventionally (method S) and very few accommodations have been sold after auction. 
* Most of the accommodations of the dataset are located to Southern Metropolitan, followed by Northern Metropolitan and Western Metropolitan.

```{r}
# see how many values there are in each day and month
days <- sort(table(df$Day), decreasing = T)
months <- sort(table(df$Month), decreasing = T)
```

```{r}
# bar plots of the frequency for the columns day and month

barplot(months, col= brewer.pal(n = 12, name = "Set3"), names = F, main = 'Frequency of house sells for each month')
legend("topright", legend = names(months), fill =brewer.pal(n = 12, name = "Set3"))

barplot(days, col= brewer.pal(n = 8, name = "Set3"), names = F, main = 'Frequency of house sells for each day of week')
legend("topright", legend = names(days), fill =brewer.pal(n = 5, name = "Set3"), cex = 1.3)
```

* The most of accommodations were sold during May, September, and months of the summer. We can "predict" that January is not significant for the model.
* Saturdays were the days when all almost of the accommodations were sold. Wednesdays and Fridays are the days which are not appeared at all in data. We can "predict" that the Day is not significant for the regression.

## Heat Maps

```{r}
# heat maps for the categorical variables

df %>% count(Type,Method ) %>% group_by(Type) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(mapping = aes(x = Type, y = Method)) +
  geom_tile(mapping = aes(fill = prop))

df %>% count(Type,Regionname ) %>% group_by(Type) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(mapping = aes(x = Type, y = Regionname)) +
  geom_tile(mapping = aes(fill = prop))

df %>% count(Method,Regionname ) %>% group_by(Method) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(mapping = aes(x = Method, y = Regionname)) +
  geom_tile(mapping = aes(fill = prop))
```

## Dummy variables for columns Type, Method, Regionname, Month, Day

```{r}
# type (the type 't' will have 0 in both columns 'h' and 'u')
df$Type_h <- ifelse(df$Type == "h", 1, 0)
df$Type_u <- ifelse(df$Type == "u", 1, 0) 

# method
df$Method_S <- ifelse(df$Method == 'S', 1, 0)
df$Method_SP <- ifelse(df$Method == 'SP', 1, 0)
df$Method_PI <- ifelse(df$Method == 'PI', 1, 0)
df$Method_VB <- ifelse(df$Method == 'VB', 1, 0)

# regionname
df$Regionname_SM <- ifelse(df$Regionname == 'Southern Metropolitan', 1, 0)
df$Regionname_NM <- ifelse(df$Regionname == 'Northern Metropolitan', 1, 0)
df$Regionname_WM <- ifelse(df$Regionname == 'Western Metropolitan', 1, 0)
df$Regionname_EM <- ifelse(df$Regionname == 'Eastern Metropolitan', 1, 0)
df$Regionname_SEM <- ifelse(df$Regionname == 'South-Eastern Metropolitan', 1, 0)
df$Regionname_EV <- ifelse(df$Regionname == 'Eastern Victoria', 1, 0)
df$Regionname_NV <- ifelse(df$Regionname == 'Northern Victoria', 1, 0)

# Month
df$Month_JAN <- ifelse(df$Month == 'Jan', 1, 0)
df$Month_FEB <- ifelse(df$Month == 'Feb', 1, 0)
df$Month_MAR <- ifelse(df$Month == 'Mar', 1, 0)
df$Month_APR <- ifelse(df$Month == 'Apr', 1, 0)
df$Month_MAY <- ifelse(df$Month == 'May', 1, 0)
df$Month_JUN <- ifelse(df$Month == 'Jun', 1, 0)
df$Month_JUL <- ifelse(df$Month == 'Jul', 1, 0)
df$Month_AUG <- ifelse(df$Month == 'Aug', 1, 0)
df$Month_SEP <- ifelse(df$Month == 'Sep', 1, 0)
df$Month_OCT <- ifelse(df$Month == 'Oct', 1, 0)
df$Month_NOV <- ifelse(df$Month == 'Nov', 1, 0)

# Day
df$Day_SAT <- ifelse(df$Day == 'Saturday', 1, 0)
df$Day_SUN <- ifelse(df$Day == 'Sunday', 1, 0)
df$Day_MON <- ifelse(df$Day == 'Monday', 1, 0)
df$Day_TUE <- ifelse(df$Day == 'Tuesday', 1, 0)
```

```{r}
#drop the Type, Method, Regionname, Day, and Month since are now dummy variables and also Lattitude and Longtitude since we have the name of the regions in the column regionname
df <- subset(df, select = -c(Type, Method, Regionname, Day, Month, Lattitude,Longtitude))
```

## Transforming the Price

```{r}
#using the logarithmic transformation on the price 
df$Price<-log(df$Price)
```

## Scaling the features

The range of the variables varies hence we have to check if it is needed to scale (standardize) them, in order to make machine learning algorithms perform better.

```{r}
# normalize only not binary columns and Year (they have only 2 unique values)
df_scaled <- df
for (i in 1:11){
  if (length(unique(df[,i])) != 2){
    df_scaled[,i] <- scale(df_scaled[,i], center =  T, scale = T)
  }
}
#head(df_scaled)
summary(df_scaled)
```

# Regression Analysis

## Linear Regression

```{r}
# 1st exploration to see which variables are the most significant provided that all predictors are included
lm.fit_full <- lm(Price ~ ., data = df)
summary(lm.fit_full)
```

```{r}
# explore how scaling affects the fitting of linear regression
lm.fit_full <- lm(Price ~ ., data = df_scaled)
summary(lm.fit_full)
```

* The p-values do not seem to be affected from scaling, hence we can move on with either the original data or the scaled ones. However, original data may help us to conclude to more clear and direct interpretations.
* Since the p-value of the F-statistic is very small we reject the null hypothesis which is the statement where there is no linearity at all between the price and the rest columns (at least 1 of the columns) at a level of significance 0.05.
* As we had said Day is not important at all, since the p-values of its dummy variables are too high. Also, we can forecast quite clearly, due to the very large corresponding p-values, that Month_JAN, Month_NOV, Propertycount and Method_SP are useless for our regression analysis.

```{r}
# do not include variables which had very large p-values
df_reduced1 <- subset(df_scaled, select = -c(Month_JAN, Propertycount, Method_SP, Month_NOV, Day_SAT, Day_SUN, Day_MON, Day_TUE))
lm.fit1 <- lm(Price ~ ., data = df_reduced1)
summary(lm.fit1)
```

```{r}
anova(lm.fit1, lm.fit_full)
```

* Since the p-value is larger than 0.05 in anova test we cannot reject the null hypothesis hence the two models are quite similar in terms of the performance. Thus, we can select the simpler model, meaning the reduced one which does not include Month_JAN, Month_NOV, Propertycount, Method_SP, Day_SAT, Day_SUN, Day_MON and Day_TUE.
* Now, with the reduced df we have that Method_PI, Method_VB are significant, whereas before they were not. Regionname_WM, Month_OCT are still not important.

```{r}
# do not include variables which are still not significant
df_reduced2 <- subset(df_reduced1, select = -c(Regionname_WM, Month_OCT))
lm.fit2 <- lm(Price ~ ., data = df_reduced2)
summary(lm.fit2)
```

```{r}
anova(lm.fit1, lm.fit2)
```

Similarly, the anova test indicates that the models provide similar performance, hence we can select the model which does not include also Regionname_WM, Month_OCT.

```{r}
# see the plots of the linear regression model

par(mfrow=c(2,2))
plot(lm.fit2)
```

From the plot of predictions and residuals we can see that the reduced model fits well, since the standardized residuals follow a normal distribution, as well as we do not have heteroscedasticity. However, we can observe high leverage points hence we should investigate more and maybe drop them.

```{r}
# leverage statistic
plot(hatvalues(lm.fit_full))
hats <- as.data.frame(hatvalues(lm.fit_full))
hats[order(-hats['hatvalues(lm.fit_full)']), ][1:20]
```

We have 3 points having much higher leverage statistic, hence we should drop them to proceed to the analysis.

```{r}
high_lev_stat <- which(hats['hatvalues(lm.fit_full)'] > 0.1) 
df_scaled <- df_scaled[-c(high_lev_stat), ]
```

```{r}
library(boot)
# original reduced data 
glm.fit <- glm(Price ~ ., data = df_reduced2)
set.seed(1)
round(cv.glm(df_reduced2, glm.fit, K = 10)$delta[1],3)
```

```{r}
# estimate the error for the models of df_scaled using the 10-fold cross validation to compare the scaled errors

glm.fit <- glm(Price ~ ., data = df_scaled)
set.seed(1)
cat('CV error for full scaled df:', round(cv.glm(df_scaled, glm.fit, K = 10)$delta[1],3))
glm.fit <- glm(Price ~ . - Month_JAN -Propertycount- Method_PI- Day_SAT- Day_SUN- Day_MON- Day_TUE, data = df_scaled)
set.seed(1)
cat('\nCV error for df without the 7 most not significant predictors:', round(cv.glm(df_scaled, glm.fit, K = 10)$delta[1], 3))
glm.fit <- glm(Price ~ . - Month_JAN -Propertycount- Method_PI- Day_SAT- Day_SUN- Day_MON- Day_TUE - Regionname_NV- Month_OCT- Month_NOV, data = df_scaled)
set.seed(1)
cat('\nCV error for scaled df without all the not significant predictors:', round(cv.glm(df_scaled, glm.fit, K = 10)$delta[1], 3))
```

Before we proceed to the algorithms for choosing the best model we could explore if polynomial regression fits better on our data. Based on the pairplots we can try to use polynomial of some orders for the column Distance and check if they provide better performance for our data.

```{r}
# use poly
lm.fit_poly <- lm(Price ~ .  -Distance + poly(Distance, 2), data = df_scaled)
summary(lm.fit_poly)
```

* Including powers of the distance column, we can see that the function lm suggests different predictors. In particular, assuming that we have all the columns in the model, in case of the data included 2nd power of column Distance, 'lm' provides that Bedroom2, Regionname_WM, Regionname_EV are significant at level of significance 0.05 whereas in the case of initial data they were not.
* The new column which is created of is very significant.

```{r}
lm.fit <- lm(Price ~ ., data = df_scaled)
anova(lm.fit, lm.fit_poly)
```

Consequently, from the anova test we reject the null hypothesis (Null hypothesis: the models are similar) at level of significance 0.05, hence the above polynomial model is better than the initial one. 

We could create more powers and check if they provide better performance.

```{r}
fit.1 <- lm(Price ~ ., data = df_scaled)
fit.2 <- lm(Price ~ .  -Distance + poly(Distance, 2), data = df_scaled)
fit.3 <- lm(Price ~ .  -Distance + poly(Distance, 3), data = df_scaled)
fit.4 <- lm(Price ~ .  -Distance + poly(Distance, 4), data = df_scaled)
fit.5 <- lm(Price ~ .  -Distance + poly(Distance, 5), data = df_scaled)
anova(fit.1, fit.2, fit.3, fit.4, fit.5)
```

The above test indicates that we should use the polynomial of 4th order.


## Forward/Backward selection of the features

### Best Subset Selection

```{r}
# just to explore the behaviour of the regsubsets between already reduced and initial data
df_new <- subset(df, select = -c(Bedroom2, Month_JAN, Propertycount, Method_SP, Day_SAT, Day_SUN, Day_MON, Day_TUE, Bedroom2, Regionname_WM, Month_OCT, Month_NOV))
df_scaled_new <- subset(df_scaled, select = -c(Bedroom2, Month_JAN, Propertycount, Method_SP, Day_SAT, Day_SUN, Day_MON, Day_TUE, Bedroom2, Regionname_WM, Month_OCT, Month_NOV))

# INCLUDE ONLY THE MOST SIGNIFICANT COLUMNS 29 columns == 28 predictors and the target column
library(leaps)
regfit_new <- regsubsets(Price ~ ., data = df_scaled_new, nvmax = 28)
reg.summary_new <- summary(regfit_new)
reg.summary_new
data.frame(
  Adj.R2 = which.max(reg.summary_new$adjr2),
  CP = which.min(reg.summary_new$cp),
  BIC = which.min(reg.summary_new$bic)
)
```

Cp and BIC give different suggestions for the best model. We have to investigate the evaluation metrics of the models and decide later on what we pursue through the model, either simpler one or the one which provides lower error.

```{r}
dim(df_scaled)
```

```{r}
# for better results we should investigate the initial data by using this method and proceed then to conclusions
regfit.full <- regsubsets(Price ~ ., data = df, nvmax = 39)
reg.summary <- summary(regfit.full)
reg.summary
data.frame(
  Adj.R2 = which.max(reg.summary$adjr2),
  CP = which.min(reg.summary$cp),
  BIC = which.min(reg.summary$bic)
)
```

```{r}
cat('Best model by using reduced data, based on the BIC\n')
cat('--------------------------------------------------\n')
for (i in 1:28){
  if (reg.summary_new$which[20,i] == TRUE){
    print(colnames(reg.summary_new$which)[i])
  }
}
```

```{r}
cat('Best model by using initial data, based on the BIC\n')
cat('--------------------------------------------------\n')
for (i in 1:39){
  if (reg.summary$which[20,i] == TRUE){
    print(colnames(reg.summary$which)[i])
  }
}
```

We can observe that although the method Best Subset Selection suggests the same number of predictors for either the initial or reduced data they are not the same ones; Method_SP, Regionname_WM and Month_NOV, which had not been significant from previous algorithm, Best Subset Selection suggests to be included to the best model. 

### Forward Stepwise Selection

```{r}
regfit.fwd <- regsubsets(Price ~ ., data = df_scaled,
    nvmax = 39, method = "forward")
regfwd.summary <- summary(regfit.fwd)
data.frame(
  Adj.R2 = which.max(regfwd.summary$adjr2),
  CP = which.min(regfwd.summary$cp),
  BIC = which.min(regfwd.summary$bic)
)
```

```{r}
cat('Best model (Forward Selection) by using initial data, based on the BIC\n')
cat('----------------------------------------------------------------------\n')
for (i in 1:39){
  if (regfwd.summary$which[20,i] == TRUE){
    print(colnames(regfwd.summary$which)[i])
  }
}
```

```{r}
# using the reduced data
regfit.fwd_new <- regsubsets(Price ~ ., data = df_scaled_new,
    nvmax = 28, method = "forward")
regfwd.summary_new <- summary(regfit.fwd_new)
data.frame(
  Adj.R2 = which.max(regfwd.summary_new$adjr2),
  CP = which.min(regfwd.summary_new$cp),
  BIC = which.min(regfwd.summary_new$bic)
)
```

```{r}
cat('Best model (Forward Selection) by using reduced data, based on the BIC\n')
cat('----------------------------------------------------------------------\n')
for (i in 1:28){
  if (regfwd.summary_new$which[20,i] == TRUE){
    print(colnames(regfwd.summary_new$which)[i])
  }
}
```

We can see that the Best Subset Selection and Forward Selection suggests the same predictors by using as input both the reduced dataframe and initial one.

### Backward Stepwise Selection

```{r}
regfit.bwd <- regsubsets(Price ~ ., data = df_scaled,
    nvmax = 39, method = "backward")
regbwd.summary <- summary(regfit.bwd)

data.frame(
  Adj.R2 = which.max(regbwd.summary$adjr2),
  CP = which.min(regbwd.summary$cp),
  BIC = which.min(regbwd.summary$bic)
)
```

```{r}
cat('Best model (Backward Selection) by using initial data, based on the BIC\n')
cat('-----------------------------------------------------------------------\n')
for (i in 1:39){
  if (regbwd.summary$which[20,i] == TRUE){
    print(colnames(regbwd.summary$which)[i])
  }
}
```

```{r}
# using the reduced data
regfit.bwd_new <- regsubsets(Price ~ ., data = df_scaled_new,
    nvmax = 28, method = "backward")
regbwd.summary_new <- summary(regfit.bwd_new)
data.frame(
  Adj.R2 = which.max(regbwd.summary_new$adjr2),
  CP = which.min(regbwd.summary_new$cp),
  BIC = which.min(regbwd.summary_new$bic)
)
```

```{r}
cat('Best model (Backward Selection) by using reduced data, based on the BIC\n')
cat('-----------------------------------------------------------------------\n')
for (i in 1:28){
  if (regbwd.summary_new$which[20,i] == TRUE){
    print(colnames(regbwd.summary_new$which)[i])
  }
}
```

* Similarly, the Backward method using the reduced dataframe suggests the same predictors with the other 2 ones.
* Although Best Subset Selection recommends same number with the Best and Backward the predictors differ.

```{r}
# best subset
regfit_poly <- regsubsets(Price ~ . -Distance + poly(Distance, 4), data = df_scaled,
    nvmax = 42)
reg.summary_poly <- summary(regfit_poly)

data.frame(
  Adj.R2 = which.max(reg.summary_poly$adjr2),
  CP = which.min(reg.summary_poly$cp),
  BIC = which.min(reg.summary_poly$bic)
)
```

```{r}
cat('Best polynomial model (Best Subset Selection) based on the BIC\n')
cat('--------------------------------------------------------------\n')
for (i in 1:42){
  if (reg.summary_poly$which[22,i] == TRUE){
    print(colnames(reg.summary_poly$which)[i])
  }
}
```

```{r}
# forward
regfit.fwd_poly <- regsubsets(Price ~ . -Distance + poly(Distance, 4), data = df_scaled,
    nvmax = 42, method = "forward")
regfwd.summary_poly <- summary(regfit.fwd_poly)

data.frame(
  Adj.R2 = which.max(regfwd.summary_poly$adjr2),
  CP = which.min(regfwd.summary_poly$cp),
  BIC = which.min(regfwd.summary_poly$bic)
)
```

```{r}
cat('Best polynomial model (Forward Selection) based on the BIC\n')
cat('--------------------------------------------------------------\n')
for (i in 1:42){
  if (regfwd.summary_poly$which[22,i] == TRUE){
    print(colnames(regfwd.summary_poly$which)[i])
  }
}
```

```{r}
# backward 
regfit.bwd_poly <- regsubsets(Price ~ . -Distance + poly(Distance, 4), data = df_scaled,
    nvmax = 42, method = "backward")
regbwd.summary_poly <- summary(regfit.bwd_poly)

data.frame(
  Adj.R2 = which.max(regbwd.summary_poly$adjr2),
  CP = which.min(regbwd.summary_poly$cp),
  BIC = which.min(regbwd.summary_poly$bic)
)
```

```{r}
cat('Best polynomial model (Backward Selection) based on the BIC\n')
cat('--------------------------------------------------------------\n')
for (i in 1:42){
  if (regbwd.summary_poly$which[24,i] == TRUE){
    print(colnames(regbwd.summary_poly$which)[i])
  }
}
```

Best Subset and Forward Selection methods suggest the same model, whereas the Backward Selection proposes a different one with 2 more predictors.

### Compare the suggested best models

#### BASED ON BIC

```{r}
# scaled data
df_best_fw_scaled <- subset(df_scaled, select = c(Price, Rooms,Distance,Postcode,Bathroom,Car,Landsize,BuildingArea,
YearBuilt, Year,Type_h,Type_u,
Method_S,Method_SP,Regionname_SM, Regionname_WM,
Regionname_EM,Regionname_SEM,Regionname_EV,Month_JUL,Month_NOV))


df_bw_scaled <- subset(df_scaled, select = c(Price,Rooms,Distance,Postcode,Bathroom,Car,Landsize,BuildingArea,
YearBuilt, Year,Type_h,Type_u,
Method_S,Method_PI,Method_VB,Regionname_SM, Regionname_NM,Regionname_EM,
Regionname_SEM,Regionname_EV,Month_JUL))

df_scaled$Distance2 <- I(df_scaled$Distance^2)
df_scaled$Distance3 <- I(df_scaled$Distance^3)

df_best_fw_poly_scaled <-subset(df_scaled, select = c(Price,Rooms,Postcode,Bathroom,Car,Landsize,BuildingArea,
YearBuilt, Year,Type_h,Type_u,
Method_S,Method_SP,Regionname_SM, Regionname_NM,Regionname_EM,Regionname_SEM,Regionname_EV,
Month_NOV,Month_JUL, Distance2, Distance3))

df_bw_poly_scaled <- subset(df_scaled, select = c(Price,Rooms,Postcode,Bathroom,Car,Landsize,BuildingArea,
YearBuilt, Year,Type_h,Type_u, 
Method_S,Method_PI,Method_VB,Regionname_SM, Regionname_NM,Regionname_EM,Regionname_SEM,Regionname_EV,
Month_APR,Month_JUL, Month_MAY,Distance2, Distance3))
```

```{r}
# Scaled data
# estimate the error of the above models using the 10-fold cross validation to compare them

cat('By using scaled data')
cat('\n------------------')
cat('\n---Based on BIC---')
cat('\n')
cat('\nCV error in case of the initial data')
cat('\n------------------------------------')

glm.fit <- glm(Price ~ ., data = df_best_fw_scaled)
set.seed(1)
cat('\nBest Subset and Forward Stepwise Selection:', round(cv.glm(df_best_fw_scaled, glm.fit, K = 10)$delta[1],3))


glm.fit <- glm(Price ~ ., data = df_bw_scaled)
set.seed(1)
cat('\nBackward Stepwise Selection::', round(cv.glm(df_bw_scaled, glm.fit, K = 10)$delta[1], 3))
cat('\n')

cat('\nCV error in case of the polynomial data')
cat('\n---------------------------------------')

glm.fit <- glm(Price ~ ., data = df_best_fw_poly_scaled)
set.seed(1)
cat('\nBest Subset Selection and Forward Stepwise Selection:', round(cv.glm(df_best_fw_poly_scaled, glm.fit, K = 10)$delta[1],3))

glm.fit <- glm(Price ~ ., data = df_bw_poly_scaled)
set.seed(1)
cat('\nBackward Stepwise Selection::', round(cv.glm(df_bw_poly_scaled, glm.fit, K = 10)$delta[1], 3))
```

```{r}
#using the unscaled data set

df_best_fw <- subset(df, select = c(Price, Rooms,Distance,Postcode,Bathroom,Car,Landsize,BuildingArea,
YearBuilt, Year,Type_h,Type_u,
Method_S,Method_SP,Regionname_SM, Regionname_WM,
Regionname_EM,Regionname_SEM,Regionname_EV,Month_JUL,Month_NOV))


df_bw <- subset(df, select = c(Price,Rooms,Distance,Postcode,Bathroom,Car,Landsize,BuildingArea,
YearBuilt, Year,Type_h,Type_u,
Method_S,Method_PI,Method_VB,Regionname_SM, Regionname_NM,Regionname_EM,
Regionname_SEM,Regionname_EV,Month_JUL))

df$Distance2 <- I(df$Distance^2)
df$Distance3 <- I(df$Distance^3)

df_best_fw_poly <-subset(df, select = c(Price,Rooms,Postcode,Bathroom,Car,Landsize,BuildingArea,
YearBuilt, Year,Type_h,Type_u,
Method_S,Method_SP,Regionname_SM, Regionname_NM,Regionname_EM,Regionname_SEM,Regionname_EV,
Month_NOV,Month_JUL, Distance2, Distance3))

df_bw_poly <- subset(df, select = c(Price,Rooms,Postcode,Bathroom,Car,Landsize,BuildingArea,
YearBuilt, Year,Type_h,Type_u, 
Method_S,Method_PI,Method_VB,Regionname_SM, Regionname_NM,Regionname_EM,Regionname_SEM,Regionname_EV,
Month_APR,Month_JUL, Month_MAY,Distance2, Distance3))

```

```{r}
# estimate the error of the above models using the 10-fold cross validation to compare them

cat('By using unscaled data')
cat('\n-------------------')
cat('\n---Based on BIC----')
cat('\n')
cat('\nCV error in case of the initial data')
cat('\n------------------------------------')

glm.fit <- glm(Price ~ ., data = df_best_fw)
set.seed(1)
cat('\nBest Subset and Forward Stepwise Selection:', format(round(cv.glm(df_best_fw, glm.fit, K = 10)$delta[1],3),big.mark=","))


glm.fit <- glm(Price ~ ., data = df_bw)
set.seed(1)
cat('\nBackward Stepwise Selection:', format(round(cv.glm(df_bw, glm.fit, K = 10)$delta[1], 3),big.mark=","))
cat('\n')

cat('\nCV error in case of the polynomial data')
cat('\n---------------------------------------')

glm.fit <- glm(Price ~ ., data = df_best_fw_poly)
set.seed(1)
cat('\nBest Subset Selection and Forward Stepwise Selection:', format(round(cv.glm(df_best_fw_poly, glm.fit, K = 10)$delta[1],3),big.mark=","))

glm.fit <- glm(Price ~ ., data = df_bw_poly)
set.seed(1)
cat('\nBackward Stepwise Selection::', format(round(cv.glm(df_bw_poly, glm.fit, K = 10)$delta[1], 3),big.mark=","))
```

It is clear that the methods provide very similar MSE. Overall so far, the best model is the one which is suggests either from Best and Forward Stepwise Selection using initial data, or the Backward Stepwise Selection using initial data.

Although the polynomial data fits better on data (based on the anova) it seems that it does not provide better MSE.

#### BASED ON Cp

```{r}
# using initial data
cat('Predictors that are not included in best model by using initial data, based on the Cp\n')
cat('-------------------------------------------------------------------------------------\n')
for (i in 1:40){
  if (reg.summary$which[29,i] == FALSE){
    print(colnames(reg.summary$which)[i])
  }
}

cat('\n')
cat('Predictors that are not included in best model (Forward Selection) by using initial data, based on the Cp\n')
cat('---------------------------------------------------------------------------------------------------------\n')
for (i in 1:40){
  if (regfwd.summary$which[31,i] == FALSE){
    print(colnames(regfwd.summary$which)[i])
  }
}

cat('\n')
cat('Predictors that are not included in best model (Backward Selection) by using initial data, based on the Cp\n')
cat('----------------------------------------------------------------------------------------------------------\n')
for (i in 1:40){
  if (regbwd.summary$which[30,i] == FALSE){
    print(colnames(regbwd.summary$which)[i])
  }
}
```

```{r}
# polynomial data
cat('Predictors that are not included in best polynomial model (Best Subset Selection) based on the Cp\n')
cat('-------------------------------------------------------------------------------------------------\n')
for (i in 1:43){
  if (reg.summary_poly$which[34,i] == FALSE){
    print(colnames(reg.summary_poly$which)[i])
  }
}

cat('Predictors that are not included in best polynomial model (Forward Selection) based on the Cp\n')
cat('---------------------------------------------------------------------------------------------\n')
for (i in 1:43){
  if (regfwd.summary_poly$which[35,i] == FALSE){
    print(colnames(regfwd.summary_poly$which)[i])
  }
}

cat('Predictors that are not included in best polynomial model (Backward Selection) based on the Cp\n')
cat('----------------------------------------------------------------------------------------------\n')
for (i in 1:43){
  if (regbwd.summary_poly$which[34,i] == FALSE){
    print(colnames(regbwd.summary_poly$which)[i])
  }
}
```

```{r}
# scaled data

df_best_scaled <- subset(df_scaled, select = -c(Bedroom2,Propertycount,Method_SP,
Month_JAN,Month_OCT,Month_NOV,Day_SAT,Day_SUN,Day_MON,Day_TUE,Distance2,Distance3))

df_fw_scaled <- subset(df_scaled, select = -c(Propertycount,Method_PI,Method_VB,
Month_JAN,Month_OCT,Day_SAT,Day_SUN,Day_TUE,Distance2,Distance3))

df_bw_scaled <- subset(df_scaled, select = -c(Bedroom2,Propertycount,Method_PI,
Regionname_NV,Month_JAN,Month_NOV,Day_SAT,Day_SUN,Day_MON,Day_TUE,Distance2,Distance3))


df_scaled$Distance4 <- I(df_scaled$Distance^4)

df_best_bw_poly_scaled <- subset(df_scaled, select = -c(Method_SP,Month_JAN,Month_OCT,Month_NOV,Day_SAT,Day_SUN,Day_MON,Day_TUE))

df_fw_poly_scaled <-subset(df_scaled, select = -c(Method_PI,Method_VB,Month_JAN,Month_OCT,Day_SAT,Day_SUN,Day_TUE))
```

```{r}
# Scaled data
# estimate the error of the above models using the 10-fold cross validation to compare them

cat('By using scaled data')
cat('\n------------------')
cat('\n---Based on Cp----')
cat('\n')
cat('\nCV error in case of the initial data')
cat('\n------------------------------------')

glm.fit <- glm(Price ~ ., data = df_best_scaled)
set.seed(1)
cat('\nBest Subset Selection:', round(cv.glm(df_best_scaled, glm.fit, K = 10)$delta[1],3)) 

glm.fit <- glm(Price ~ ., data = df_fw_scaled)
set.seed(1)
cat('\nForward Stepwise Selection:', round(cv.glm(df_fw_scaled, glm.fit, K = 10)$delta[1], 3))

glm.fit <- glm(Price ~ ., data = df_bw_scaled)
set.seed(1)
cat('\nBackward Stepwise Selection:', round(cv.glm(df_bw_scaled, glm.fit, K = 10)$delta[1], 3))

cat('\n')
cat('\nCV error in case of the polynomial data')
cat('\n---------------------------------------')

glm.fit <- glm(Price ~ ., data = df_best_bw_poly_scaled)
set.seed(1)
cat('\nBest Subset and Backward Stepwise Selection:', round(cv.glm(df_best_bw_poly_scaled, glm.fit, K = 10)$delta[1],3))

glm.fit <- glm(Price ~ ., data = df_fw_poly_scaled)
set.seed(1)
cat('\nForward Stepwise Selection:', round(cv.glm(df_fw_poly_scaled, glm.fit, K = 10)$delta[1],3))
```

```{r}
# unscaled data

df_best <- subset(df, select = -c(Bedroom2,Propertycount,Method_SP,
Month_JAN,Month_OCT,Month_NOV,Day_SAT,Day_SUN,Day_MON,Day_TUE,Distance2,Distance3))

df_fw <- subset(df, select = -c(Propertycount,Method_PI,Method_VB,
Month_JAN,Month_OCT,Day_SAT,Day_SUN,Day_TUE,Distance2,Distance3))

df_bw <- subset(df, select = -c(Bedroom2,Propertycount,Method_PI,
Regionname_NV,Month_JAN,Month_NOV,Day_SAT,Day_SUN,Day_MON,Day_TUE,Distance2,Distance3))


df$Distance4 <- I(df$Distance^4)

df_best_bw_poly <- subset(df, select = -c(Method_SP,Month_JAN,Month_OCT,Month_NOV,Day_SAT,Day_SUN,Day_MON,Day_TUE))

df_fw_poly <-subset(df, select = -c(Method_PI,Method_VB,Month_JAN,Month_OCT,Day_SAT,Day_SUN,Day_TUE))
```

```{r}
# unscaled data
# estimate the error of the above models using the 10-fold cross validation to compare them

cat('By using unscaled data')
cat('\n-------------------')
cat('\n----Based on Cp----')
cat('\n')
cat('\nCV error in case of the initial data')
cat('\n------------------------------------')

glm.fit <- glm(Price ~ ., data = df_best)
set.seed(1)
cat('\nBest Subset Selection:', round(cv.glm(df_best, glm.fit, K = 10)$delta[1],3)) 

glm.fit <- glm(Price ~ ., data = df_fw)
set.seed(1)
cat('\nForward Stepwise Selection:', round(cv.glm(df_fw, glm.fit, K = 10)$delta[1], 3))

glm.fit <- glm(Price ~ ., data = df_bw)
set.seed(1)
cat('\nBackward Stepwise Selection:', round(cv.glm(df_bw, glm.fit, K = 10)$delta[1], 3))

cat('\n')
cat('\nCV error in case of the polynomial data')
cat('\n---------------------------------------')

glm.fit <- glm(Price ~ ., data = df_best_bw_poly)
set.seed(1)
cat('\nBest Subset and Backward Stepwise Selection:', round(cv.glm(df_best_bw_poly, glm.fit, K = 10)$delta[1],3))

glm.fit <- glm(Price ~ ., data = df_fw_poly)
set.seed(1)
cat('\nForward Stepwise Selection:', round(cv.glm(df_fw_poly, glm.fit, K = 10)$delta[1],3))
```

Thus, the best models, so far, are the polynomial ones which are suggested based on Cp and they provide about 0.264 error in scaled data. Specifically the models have either 34 or 35 features, hence we could select the simpler one from Best Subset and Backward Stepwise Selection.

```{r}
model <- data.frame()
for (i in 1:43){
  if (reg.summary_poly$which[34,i] == TRUE){
    model[nrow(model)+1,1] <- colnames(reg.summary_poly$which)[i]
  }
}
colnames(model)[1] <- 'Predictors'
model
```

## Other Regression models

```{r}
library(randomForest)
library(lattice)
library(caret)

#train and test sets for the scaled dataset
set.seed(1)
sample <- sample(c(TRUE, FALSE), nrow(df_scaled), replace=TRUE, prob=c(0.8,0.2))
train <- df_scaled[sample,]
test <- df_scaled[!sample,]

#Random Forest
rf <- randomForest(Price~., data=train, proximity=TRUE) 
rf_predict <- predict(rf, test)

print(rf)
library("Metrics")
#RMSE
RMSE <-rmse(rf_predict, test$Price)

#mse
(RMSE)^2

# R2
cor(test$Price, rf_predict) ^ 2
```

As we expected, the MSE (at about 0.13) is less than the one of the suggested models from the above models.

###**Boosted Trees--Stochastic Gradient Boosting**

After getting good results with random forest we decide to implement Stochastic Gradient Boosting

```{r}
df_gdb <- df
library(gbm)
library(lattice)
library(caret)


#model <- gbm(Price ~ ., data = df_gdb) #Simple Model
#model

#Without Preprocessing (Centering, Scaling)
set.seed(1)
df_gdb <- df_gdb[, -c(26)] # remove column 26 (Month_JAN)
model <- train(
  Price ~ .,
  data = df_gdb,
  method = 'gbm',
  verbose = FALSE
)
model
```

Try with Preprocessing (Model2)

```{r}
set.seed(1)

model2 <- train(
  Price ~ .,
  data = df_gdb,
  method = 'gbm',
  preProcess = c("center", "scale"),
  verbose = FALSE
)
model2
```

Training& Testing (Model_3)

```{r}
set.seed(1)
#80/20Split

inTraining <- createDataPartition(df_gdb$Price, p = .80, list = FALSE)
training <- df_gdb[inTraining,]
testing  <- df_gdb[-inTraining,]

#fit our model again using only the training data
set.seed(1)
model3 <- train(
  Price ~ .,
  data = training,
  method = 'gbm',
  preProcess = c("center", "scale"),
  verbose = FALSE
)
model3
```

```{r}
#predict using the model3
predictions = predict(model3, newdata = testing)

# RMSE
sqrt(mean((testing$Price - predictions)^2))
# R2
cor(testing$Price, predictions) ^ 2
```

We try with CV (Model 4)

```{r}
set.seed(1) #10 Folds CV

ctrl <- trainControl(
  method = "cv",
  number = 10
)

# set.seed(1)
model4 <- train(
  Price ~ .,
  data = training,
  method = 'gbm',
  preProcess = c("center", "scale"),
  trControl = ctrl,
  verbose = FALSE
)
model4

plot(model4) #small improvement 
```

```{r}
predictions = predict(model4, newdata = testing)

# RMSE
sqrt(mean((testing$Price - predictions)^2))

# R2
cor(testing$Price, predictions) ^ 2
```

Tuning Hyperparamters (Model5)

```{r}
set.seed(1)

tuneGrid <- expand.grid(
 n.trees = c(50, 100),
 interaction.depth = c(1, 2),
 shrinkage = 0.1,
 n.minobsinnode = 10
)

model5 <- train(
  Price ~ .,
  data = df_gdb,
  method = 'gbm',
  preProcess = c("center", "scale"),
  trControl = ctrl,
  tuneGrid = tuneGrid,
  verbose = FALSE
)
model5
```

```{r}
predictions = predict(model5, newdata = testing)

# RMSE
sqrt(mean((testing$Price - predictions)^2))
# R2
cor(testing$Price, predictions) ^ 2
```

```{r}
library(gridExtra)
plot2 <- plot(model2)
plot3 <- plot(model3)
plot4 <- plot(model4)
plot5 <- plot(model5)

# assuming you have 4 plots saved as p1, p2, p3, and p4
grid.arrange(plot2, plot3, plot4, plot5, ncol = 2)
```

We can conclude that stochastic gradient boosting give the best results so far

## Principal Components Regression

```{r}
library(pls)
x <- model.matrix(Price ~ .,df_scaled)[, -1]
y <- df_scaled$Price

set.seed(1)
train <- sample(1:nrow(x), nrow(x) / 2)
test <- (-train)
y.test <- y[test]

pcr.fit <- pcr(Price ~ ., data = df_scaled, subset = train, validation = "CV")
validationplot(pcr.fit, val.type = "MSEP")
summary(pcr.fit)
```

```{r}
# we could choose the number of components being equal to 41
pcr.pred <- predict(pcr.fit, x[test, ], ncomp=41)
mse = mean((pcr.pred - y.test)^2)
mse
```

```{r}
# compare the error of PCR using the best number of components with the error of previous Cp best model

mse - 0.264

```

We conclude that the best model so far (apart from the random forest method) is the previous one, from linear (polynomial) model based on Cp.

# Partial Least Squares

```{r}
set.seed(1)
pls.fit <- plsr(Price ~ ., data = df_scaled, subset = train, validation = "CV")
summary(pls.fit)
```

```{r}
validationplot(pls.fit, val.type = "MSEP")

pls.pred <- predict(pls.fit, x[test,])
err.pls <- mean((pls.pred-y.test)^2)
err.pls
```

```{r}
#with 34 components 
pls.fit <- plsr(Price ~ ., data = df_scaled,ncomp = 34)
summary(pls.fit)

pls.pred <- predict(pls.fit, x[test,], ncomp=34)
err.pls <- mean((pls.pred-y.test)^2)
err.pls
```

# Lasso and Ridge Regression

```{r}
library(glmnet)
# using the scaled data set
x <- model.matrix(Price ~ ., df_scaled)[, -1]
y <- df_scaled$Price
```

```{r}
# RIDGE
grid <- 10^seq(10, -2, length = 100)
ridge.mod <- glmnet(x, y, alpha = 0, lambda = grid)
dim(coef(ridge.mod))
```

```{r}
# train and test
set.seed(1)
train <- sample(1:nrow(x), nrow(x) / 2)
test <- (-train)
y.test <- y[test]
```

```{r}
ridge.mod <- glmnet(x[train, ], y[train], alpha = 0,
    lambda = grid, thresh = 1e-12)
ridge.pred <- predict(ridge.mod, s = 2, newx = x[test, ])
mean((ridge.pred - y.test)^2)
```

```{r}
set.seed(1)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 0)
plot(cv.out)
```

```{r}
#best lambda proposed is:
bestlam <- cv.out$lambda.min
bestlam
```

```{r}
#using the best lambda
ridge.pred <- predict(ridge.mod, s = bestlam,
    newx = x[test, ])
mean((ridge.pred - y.test)^2)
```

```{r}
bestlam1se <- cv.out$lambda.1se
bestlam1se

# the best lambda according to one standard error rule give a worst test MSE
ridge.pred1se <- predict(ridge.mod, s = bestlam1se,
    newx = x[test, ])
mean((ridge.pred1se - y.test)^2)

out <- glmnet(x, y, alpha = 0)
predict(out, type = "coefficients", s = bestlam)[1:40, ]
```

```{r}
# LASSO

lasso.mod <- glmnet(x[train, ], y[train], alpha = 1,
    lambda = grid)
plot(lasso.mod)
```

```{r}
set.seed(1)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1)
plot(cv.out)
```

```{r}
#using the best lambda
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod, s = bestlam,
    newx = x[test, ])
mean((lasso.pred - y.test)^2)
```

```{r}
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out, type = "coefficients",
    s = bestlam)[1:40, ]
lasso.coef
```

```{r}
#17 coefficients are equal to 0, here 25 are printed
lasso.coef[lasso.coef != 0]
```








































